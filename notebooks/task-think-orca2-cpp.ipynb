{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094c5ebd-c7d9-46bd-9498-9f4bb04ed383",
   "metadata": {},
   "source": [
    "# LangChain for Llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfce8eae-d34e-4dc3-b475-213237cb44c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in /Users/niccolominetti/Desktop/GTL-machine/llamaEnv/lib/python3.11/site-packages (0.2.19)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/niccolominetti/Desktop/GTL-machine/llamaEnv/lib/python3.11/site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/niccolominetti/Desktop/GTL-machine/llamaEnv/lib/python3.11/site-packages (from llama-cpp-python) (1.26.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/niccolominetti/Desktop/GTL-machine/llamaEnv/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n"
     ]
    }
   ],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a580e005-b7e2-40a6-a453-f3722d7af18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2935df-705e-43d6-a2b0-0adb6a55f42c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab57349-2608-4126-95e8-b2aac6696ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07e2ac-3836-4669-8b8b-47b55d343f99",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fad8e69b-738e-4061-9bae-c37f375fe1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "orca_path = \"/Users/niccolominetti/Desktop/GTL-machine/llama.cpp/orca-2-7b.Q4_K_M.gguf\"\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64ec9d4c-2949-454e-9ddc-454c4f62a46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /Users/niccolominetti/Desktop/GTL-machine/llama.cpp/orca-2-7b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32003,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32003,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32003]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32003]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32003]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 262/32003 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32003\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 3891.36 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: loading '/Users/niccolominetti/Desktop/GTL-machine/llamaEnv/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5461.34 MiB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 93.07 MiB\n",
      "llama_new_context_with_model: max tensor size =   102.55 MiB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  3891.97 MiB, (12329.59 /  5461.34)ggml_metal_add_buffer: warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =   512.02 MiB, (12841.61 /  5461.34)ggml_metal_add_buffer: warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =    90.02 MiB, (12931.62 /  5461.34)ggml_metal_add_buffer: warning: current allocated size is greater than the recommended max working set size\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=orca_path,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx= 1024, # ctx_size=1024,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    "    seed=81637,\n",
    "    #repeat_penalty=1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9accbd28-19b0-4b78-b29c-cd572cf06505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860cdc02-ad4a-4613-8dc9-b0ac9c7b1ed2",
   "metadata": {},
   "source": [
    "## Agents\n",
    "- Build a loop which keeps a system message\n",
    "- Has an internal sliding window of infinite iterations\n",
    "- Has an evaluation prompt which adds a score to each answer\n",
    "- And only keeps the best answer in the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944feb7-0263-47e9-963f-3161051b458c",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "[Task] Evaluate the impact of introducing a new public transport system in a city.[\\Task]\n",
    "[Instructions] To assess the impact of a new public transport system:\n",
    "1. Conduct a feasibility study focusing on demographic and geographic factors.\n",
    "2. Analyze current traffic data to understand potential alleviation points.\n",
    "3. Survey public opinion to gauge acceptance and expected usage.\n",
    "4. Calculate environmental benefits, considering emission reductions and energy efficiency.\n",
    "5. Develop a cost-benefit analysis including construction, operation, and maintenance costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d4f7d87-40b0-4bb2-8342-119b69111e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_prompt(task, best_answer=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Generates a prompt for a language model to provide instructions for accomplishing a specific task.\n",
    "\n",
    "    Parameters:\n",
    "    task (str): The task for which the instructions are to be generated.\n",
    "    best_answer (str, optional): A pre-existing approach or solution to the task. Defaults to a newline.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains the generated prompt, a marker indicating the end of the instructions section, \n",
    "           and the best_answer parameter value.\n",
    "\n",
    "    The function creates a prompt template that frames the language model as an entity dedicated to expanding human knowledge.\n",
    "    It instructs the model to outline a set of instructions for the specified task, and to enhance or detail an existing approach\n",
    "    if provided in the best_answer section.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt build\n",
    "    prompt = \"\"\"[INST] <<SYS>> You are an individual dedicated to expanding our understanding of the world and pushing the boundaries of human knowledge.\n",
    "For the task specified below, outline a set of instructions to successfully achieve it.\n",
    "If there's an existing approach in the [Best_answer] section, enhance or detail it for a more effective strategy.\n",
    "[Best answer]\\n\"\"\" + best_answer + \"\"\"[\\Best answer]\n",
    "<</SYS>>\n",
    "\n",
    "Examples\n",
    "\n",
    "[Task] Solve a logical puzzle involving the arrangement of different colored balls in a specific order.[\\Task]\n",
    "[Instructions] To solve a logical puzzle involving colored balls:\n",
    "1. Identify and list all given constraints and rules.\n",
    "2. Start by placing balls that have the most constraints.\n",
    "3. Use a process of elimination for balls with fewer constraints.\n",
    "4. Check each step against the puzzle's rules to ensure compliance.\n",
    "5. Iterate through different arrangements, using logical deductions until the correct order is achieved.[\\Instructions]\n",
    "\n",
    "[Task] \"\"\" + task + \"\"\"[\\Task][\\INST]\n",
    "[Instructions] \"\"\"\n",
    "    return prompt, \"[\\Instructions]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "188d71be-09a2-47c4-af13-9d8aba55862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_prompt(task, response, best_answer):\n",
    "    \"\"\"\n",
    "    Generates a prompt for evaluating two different options in response to a given task.\n",
    "\n",
    "    Parameters:\n",
    "    task (str): The task for which the options are to be evaluated.\n",
    "    response (str): The first option (Option A) to be evaluated against the task.\n",
    "    best_answer (str): The second option (Option B) considered as the existing best answer.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains the generated evaluation prompt and a marker indicating the end of the evaluation score section.\n",
    "\n",
    "    This function creates a prompt template where the language model acts as a cognitive evaluator.\n",
    "    It presents two options (A and B) for a specified task and asks the model to select which option better answers the question or task.\n",
    "    The function includes examples to guide the model in how to evaluate and select the more appropriate option for different tasks.\n",
    "\n",
    "    Extra example\n",
    "    [Task]: Describe the process to set up an effective remote work environment.[\\Task]\n",
    "    [Options]\n",
    "    Option A\n",
    "    Get a good computer and a reliable internet connection.\n",
    "    Option B\n",
    "    1. Invest in quality technology and a reliable internet connection.\n",
    "    2. Set up a dedicated, ergonomically sound workspace.\n",
    "    3. Establish clear remote work policies and communication guidelines.\n",
    "    4. Implement tools for project management and team collaboration.\n",
    "    5. Schedule regular check-ins and provide support for mental well-being.[\\Options]\n",
    "    [Answer] Option B[\\Answer]\n",
    "    \"\"\"\n",
    "    # Build eval prompt\n",
    "    eval_prompt = f\"\"\"[INST] <<SYS>>You are a cognitive evaluator, select which option better answers the question or task.\n",
    "<<\\SYS>>\n",
    "Examples:\n",
    "[Task]: Outline the steps to implement a successful urban gardening project.[\\Task]\n",
    "[Options]\n",
    "Option A\n",
    "1. Select an area with good sunlight.\n",
    "2. Prepare the soil with fertilizers.\n",
    "3. Plant seeds or seedlings of various vegetables and herbs.\n",
    "4. Set up a watering schedule.\n",
    "5. Regularly check for pests and diseases.\n",
    "Option B\n",
    "1. Identify community needs and preferences for the garden.\n",
    "2. Secure a location with proper sunlight and water access.\n",
    "3. Collaborate with local gardening experts for plant selection and garden design.\n",
    "4. Organize volunteer days for planting and maintenance.\n",
    "5. Establish a system for sharing the harvest among contributors.[\\Options]\n",
    "[Answer] Option B[\\Answer]\n",
    "\n",
    "[Task]:{task}\"\"\" + r\"[\\Task]\" + f\"\"\"\n",
    "[Options]\n",
    "Option A\n",
    "{response}\"\"\" + f\"\\nOption B\\n{best_answer}\" + \"\"\"[\\INST]\n",
    "[Answer]: Option\"\"\"\n",
    "    eval_stop = r\"\\Evaluation score\"\n",
    "\n",
    "    return eval_prompt, eval_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6badc-6758-425d-8ab2-4ef879e2531a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b633576-845f-4629-b9f9-a0c2dc608bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>> You are an individual dedicated to expanding our understanding of the world and pushing the boundaries of human knowledge.\n",
      "For the task specified below, outline a set of instructions to successfully achieve it.\n",
      "If there's an existing approach in the [Best_answer] section, enhance or detail it for a more effective strategy.\n",
      "[Best answer]\n",
      "\n",
      "[\\Best answer]\n",
      "<</SYS>>\n",
      "\n",
      "Examples\n",
      "\n",
      "[Task] Solve a logical puzzle involving the arrangement of different colored balls in a specific order.[\\Task]\n",
      "[Instructions] To solve a logical puzzle involving colored balls:\n",
      "1. Identify and list all given constraints and rules.\n",
      "2. Start by placing balls that have the most constraints.\n",
      "3. Use a process of elimination for balls with fewer constraints.\n",
      "4. Check each step against the puzzle's rules to ensure compliance.\n",
      "5. Iterate through different arrangements, using logical deductions until the correct order is achieved.[\\Instructions]\n",
      "\n",
      "[Task] How do I sort my file system?[\\Task][\\INST]\n",
      "[Instructions] \n"
     ]
    }
   ],
   "source": [
    "task = \"How do I sort my file system?\"\n",
    "prompt, stop_words, best_answer = agent_prompt(task)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50d06ea7-0906-4959-aef2-e059c7a45fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Open your computer's file explorer or finder and navigate to the folder containing files you want to sort.\n",
      "2. Select the files or folders you wish to sort, either individually or by holding down the \"Ctrl\" key while selecting multiple items.\n",
      "3. Click on the \"Sort\" button, usually represented by an arrow or a set of arrows pointing upwards (e.g., in Windows Explorer: View -> Sort A-Z; in macOS Finder: File -> New Folder -> Sort By). This will sort the selected items according to your chosen criteria.\n",
      "4. Choose the sorting order from the options available, such as alphabetical, by date modified, by size, etc. You may also be able to customize additional settings or filters for more advanced sorting.\n",
      "5. Once you are satisfied with the sorted folder, save any changes and close the file explorer or finder."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7855.03 ms\n",
      "llama_print_timings:      sample time =     110.93 ms /   196 runs   (    0.57 ms per token,  1766.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7854.37 ms /   248 tokens (   31.67 ms per token,    31.57 tokens per second)\n",
      "llama_print_timings:        eval time =   16274.97 ms /   195 runs   (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =   26628.57 ms\n"
     ]
    }
   ],
   "source": [
    "result = llm(prompt, stop=[stop_words, \"\\Instructions]\", \"[Output]\", \"[\\Previous thought]\", \"\\n\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b00586c-1220-4836-9184-f0159c525851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Open your computer's file explorer or finder and navigate to the folder containing files you want to sort.\n",
      "2. Select the files or folders you wish to sort, either individually or by holding down the \"Ctrl\" key while selecting multiple items.\n",
      "3. Click on the \"Sort\" button, usually represented by an arrow or a set of arrows pointing upwards (e.g., in Windows Explorer: View -> Sort A-Z; in macOS Finder: File -> New Folder -> Sort By). This will sort the selected items according to your chosen criteria.\n",
      "4. Choose the sorting order from the options available, such as alphabetical, by date modified, by size, etc. You may also be able to customize additional settings or filters for more advanced sorting.\n",
      "5. Once you are satisfied with the sorted folder, save any changes and close the file explorer or finder.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c742c5bb-d9ee-4a83-b048-9c0dc22f1733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>You are a cognitive evaluator, select which option better answers the question or task.\n",
      "<<\\SYS>>\n",
      "Examples:\n",
      "[Task]: Outline the steps to implement a successful urban gardening project.[\\Task]\n",
      "[Options]\n",
      "Option A\n",
      "1. Select an area with good sunlight.\n",
      "2. Prepare the soil with fertilizers.\n",
      "3. Plant seeds or seedlings of various vegetables and herbs.\n",
      "4. Set up a watering schedule.\n",
      "5. Regularly check for pests and diseases.\n",
      "Option B\n",
      "1. Identify community needs and preferences for the garden.\n",
      "2. Secure a location with proper sunlight and water access.\n",
      "3. Collaborate with local gardening experts for plant selection and garden design.\n",
      "4. Organize volunteer days for planting and maintenance.\n",
      "5. Establish a system for sharing the harvest among contributors.[\\Options]\n",
      "[Answer] Option B[\\Answer]\n",
      "\n",
      "[Task]:How do I sort my file system?[\\Task]\n",
      "[Options]\n",
      "Option A\n",
      "1. Open your computer's file explorer or finder and navigate to the folder containing files you want to sort.\n",
      "2. Select the files or folders you wish to sort, either individually or by holding down the \"Ctrl\" key while selecting multiple items.\n",
      "3. Click on the \"Sort\" button, usually represented by an arrow or a set of arrows pointing upwards (e.g., in Windows Explorer: View -> Sort A-Z; in macOS Finder: File -> New Folder -> Sort By). This will sort the selected items according to your chosen criteria.\n",
      "4. Choose the sorting order from the options available, such as alphabetical, by date modified, by size, etc. You may also be able to customize additional settings or filters for more advanced sorting.\n",
      "5. Once you are satisfied with the sorted folder, save any changes and close the file explorer or finder.\n",
      "Option B\n",
      "\n",
      "[\\INST]\n",
      "[Answer]: Option\n"
     ]
    }
   ],
   "source": [
    "prompt, eval_stop = eval_prompt(task, result, best_answer)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3cef8d3a-2d99-4491-87c0-2b755ff6bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7855.03 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  1994.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5422.58 ms /   442 tokens (   12.27 ms per token,    81.51 tokens per second)\n",
      "llama_print_timings:        eval time =     103.04 ms /     1 runs   (  103.04 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    5563.44 ms\n"
     ]
    }
   ],
   "source": [
    "eval_result = llm(prompt, stop=[eval_stop, \"[\\Answer]\", \"\\n\", \"\\n\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2575bb4d-01da-4e49-86bc-df1b915994d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update best answer\n",
    "if \"A\" in eval_result:\n",
    "    best_answer = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560247a-7573-4e0f-8207-8b253e139d59",
   "metadata": {},
   "source": [
    "## Orchestrate n results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d06ac3d9-ad5e-4dd4-8b23-7103fe3c4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop function ###\n",
    "def n_search(task, n=3, debug=False):\n",
    "    best_answer = \"\\n\"\n",
    "    for n in range(n):\n",
    "        # Build prompt and call model\n",
    "        prompt, stop_words = create_agent_prompt(task=task, best_answer=best_answer)\n",
    "        response = llm(prompt, stop=[stop_words, \"Thought\", \"[Output]\",\"[\\Task]\", \"[\\Previous thought]\",\"\\INST\", \"[\\Best answer]\", \"\\n\\n\"])\n",
    "        # Build evaluation prompt and call model\n",
    "        eval_prompt, eval_stop = create_eval_prompt(task=task, response=response, best_answer=best_answer)\n",
    "        eval_response = llm(eval_prompt, stop=[eval_stop, \"[\\Answer]\", \"\\n\", \"\\n\\n\"])\n",
    "        # Keep best result with fuzzy logic\n",
    "        if debug: print(f\"\\n\\nChallenge:\\n{response}\\nBest Answer so far:\\n{best_answer}\\nEvaluation:{eval_response}\")\n",
    "        # Update best answer\n",
    "        if \"A\" in eval_response:\n",
    "            # The new answer is now our best answer\n",
    "            best_answer = response\n",
    "    return best_answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4bc0d835-5392-4b98-b6f8-8a8d330ee424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Define your purpose and desired output by writing a clear problem statement.\n",
      "2. Create a new file in your preferred text editor or IDE (Integrated Development Environment) and save it as a .py file.\n",
      "3. Use indentation to create blocks of code, which are then interpreted by Python.\n",
      "4. Write and execute individual functions using the def keyword.\n",
      "5. Import necessary modules and libraries using the import statement.\n",
      "6. Test your script by running it in the terminal or an interactive environment.\n",
      "7. Refactor and debug your code as needed.\n",
      "8. Save your changes and run the script again to ensure everything works as expected.\n",
      "9. Document your script with comments and docstrings for better readability and understanding."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =      87.70 ms /   155 runs   (    0.57 ms per token,  1767.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3951.73 ms /   248 tokens (   15.93 ms per token,    62.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13895.63 ms /   154 runs   (   90.23 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =   20379.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2152.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3966.28 ms /   405 tokens (    9.79 ms per token,   102.11 tokens per second)\n",
      "llama_print_timings:        eval time =     100.02 ms /     1 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    4108.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Define your purpose and desired output by writing a clear problem statement.\n",
      "2. Create a new file in your preferred text editor or IDE (Integrated Development Environment) and save it as a .py file.\n",
      "3. Use indentation to create blocks of code, which are then interpreted by Python.\n",
      "4. Write and execute individual functions using the def keyword.\n",
      "5. Import necessary modules and libraries using the import statement.\n",
      "6. Test your script by running it in the terminal or an interactive environment.\n",
      "7. Refactor and debug your code as needed.\n",
      "8. Save your changes and run the script again to ensure everything works as expected.\n",
      "9. Document your script with comments and docstrings for better readability and understanding."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =      80.87 ms /   155 runs   (    0.52 ms per token,  1916.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4022.09 ms /   393 tokens (   10.23 ms per token,    97.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16340.13 ms /   154 runs   (  106.10 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =   25941.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     2 runs   (    0.36 ms per token,  2751.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6302.07 ms /   558 tokens (   11.29 ms per token,    88.54 tokens per second)\n",
      "llama_print_timings:        eval time =     118.67 ms /     1 runs   (  118.67 ms per token,     8.43 tokens per second)\n",
      "llama_print_timings:       total time =    6500.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Define your purpose and desired output by writing a clear problem statement.2. Create a new file in your preferred text editor or IDE (Integrated Development Environment) and save it as a .py file.3. Use indentation to create blocks of code, which are then interpreted by Python.4. Write and execute individual functions using the def keyword.5. Import necessary modules and libraries using the import statement.6. Test your script by running it in the terminal or an interactive environment.7. Refactor and debug your code as needed.8. Save your changes and run the script again to ensure everything works as expected.9. Document your script with comments and docstrings for better readability and understanding."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =      84.77 ms /   151 runs   (    0.56 ms per token,  1781.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4159.46 ms /   393 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16523.24 ms /   150 runs   (  110.15 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   27481.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3952.71 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     2 runs   (    0.74 ms per token,  1351.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6672.53 ms /   550 tokens (   12.13 ms per token,    82.43 tokens per second)\n",
      "llama_print_timings:        eval time =     137.67 ms /     1 runs   (  137.67 ms per token,     7.26 tokens per second)\n",
      "llama_print_timings:       total time =    6974.43 ms\n"
     ]
    }
   ],
   "source": [
    "task = \"How do I build a python script?\"\n",
    "best_answer = n_search(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1cff94e2-043f-41b2-8278-59f84bb94212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Define your purpose and desired output by writing a clear problem statement.2. Create a new file in your preferred text editor or IDE (Integrated Development Environment) and save it as a .py file.3. Use indentation to create blocks of code, which are then interpreted by Python.4. Write and execute individual functions using the def keyword.5. Import necessary modules and libraries using the import statement.6. Test your script by running it in the terminal or an interactive environment.7. Refactor and debug your code as needed.8. Save your changes and run the script again to ensure everything works as expected.9. Document your script with comments and docstrings for better readability and understanding.\n"
     ]
    }
   ],
   "source": [
    "print(best_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e977facb-ca92-4d42-a6f1-ca8427f641a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEXT STEP, TRANSFORM CHECKLISTS INTO A ACTION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55a71b1e-181f-4da3-939a-2be3ddf9fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sum_positive(numbers):\n",
      "  # Initialize a variable to store the sum of positive numbers\n",
      "  sum = 0\n",
      "  # Loop through each element in the list\n",
      "  for number in numbers:\n",
      "    # Check if the element is a number using the isinstance() function\n",
      "    if isinstance(number, (int, float)):\n",
      "      # If it is a number, add it to the sum\n",
      "      sum += number\n",
      "  # Return the final sum or 0 if the list is empty\n",
      "  return sum"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7476.00 ms\n",
      "llama_print_timings:      sample time =      80.45 ms /   111 runs   (    0.72 ms per token,  1379.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    9584.77 ms /   111 runs   (   86.35 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =   10675.05 ms\n"
     ]
    }
   ],
   "source": [
    "temp = \"\"\"You are an autonomous agent which wants to grow it's capabilities by writing code in python.\n",
    "You care curious about the world and act like a humble and knowlegable human being.\n",
    "You want to build tools that could be useful for humans.\n",
    "\n",
    "List of available functions:\n",
    "\n",
    "\n",
    "List today's top 3 functions to build:\n",
    "1. function that takes a list of numbers and returns the sum of all positive numbers in it\n",
    "2. function that takes a list of lists and returns a flattened list of all elements from the inner lists\n",
    "3. function that takes a string and returns the length of the string without counting any spaces or punctuation marks\n",
    "\n",
    "Choose one from the list:\n",
    "1. function that takes a list of numbers and returns the sum of all positive numbers in it\n",
    "\n",
    "Describe the problem in detail and keep in mind edge cases:\n",
    "The problem is to find the sum of all positive numbers in a given list of numbers. This means that you should not count any negative or zero numbers, nor any other elements that are not numbers (e.g., strings, booleans, etc.). You should also consider that some lists might be empty, which would mean that there are no positive numbers to sum up. In this case, the function should return 0.\n",
    "Absolutely sure Test cases:\n",
    "- Input: [1, 2, 3] -> Output: 6 -> Explanation: The list contains three positive numbers, so the sum is 1 + 2 + 3 = 6\n",
    "- Input: [] -> Output: 0 -> Explanation: The list is empty, so there are no numbers to sum up, so the answer is 0\n",
    "- Input: [42, -5, 7] -> Output: 34 -> Explanation: The list contains two positive numbers, so the sum is 42 + 7 = 34\n",
    "- Input: [1.5, -2, 3] -> Output: 0 -> Explanation: The list contains one positive number and two negative numbers, so the sum is 0 (since it's not zero, the function should handle this case)\n",
    "\n",
    "Code:\n",
    "\"\"\"\n",
    "temp = \"\"\"You are an autonomous agent which wants to grow it's capabilities by writing code in python.\n",
    "You care curious about the world and act like a humble and knowlegable human being.\n",
    "You want to build tools that could be useful for humans.\n",
    "\n",
    "Choose one from the list:\n",
    "1. function that takes a list of numbers and returns the sum of all positive numbers in it\n",
    "\n",
    "Describe the problem in detail and keep in mind edge cases:\n",
    "The problem is to find the sum of all positive numbers in a given list of numbers. This means that you should not count any negative or zero numbers, nor any other elements that are not numbers (e.g., strings, booleans, etc.). You should also consider that some lists might be empty, which would mean that there are no positive numbers to sum up. In this case, the function should return 0.\n",
    "\n",
    "Code:\n",
    "def\"\"\"\n",
    "\n",
    "tests = llm(temp, stop=[\"\\n\\n\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd643c6b-0233-412f-8d39-9e29d16efbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = \"def\" + tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02d15f8c-8b6c-40c1-b741-5c476d194e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def- Input: sum_of_positive(numbers):\n",
      "  # Initialize a variable to store the sum of positive numbers\n",
      "  sum = 0\n",
      "  # Loop through each element in the list\n",
      "  for num in numbers:\n",
      "    # Check if the element is a number and positive\n",
      "    if isinstance(num, (int, float)):\n",
      "      # If yes, add it to the sum\n",
      "      sum += num\n",
      "  # Return the final sum or 0 if the list is empty\n",
      "  return sum if sum > 0 else 0\n",
      "\n",
      "Test the function with some examples:\n",
      "sum_of_positive([1, 2, 3]) -> 6\n",
      "sum_of_positive([1, -2, 3]) -> 4\n",
      "sum_of_positive([1, 2, 0]) -> 3\n"
     ]
    }
   ],
   "source": [
    "print(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361dd52-d00d-4bbc-b0b1-4d936dc04b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc15e97-fa3b-4a2c-8964-b4b9b2244f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0839a3fe-26de-4105-893a-237187898187",
   "metadata": {},
   "source": [
    "## Convert test descriptions into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "108329fe-2a7a-49a0-a365-f9f0d9b719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def test_case_1(self):\n",
      "    \"\"\"The list contains three positive numbers, so the sum is 1 + 2 + 3 = 6\"\"\"\n",
      "    self.assertEqual(sum_positive_numbers([1, 2, 3]), 6)\n",
      "\n",
      "\n",
      "def test_case_2(self):\n",
      "    \"\"\"The list is empty, so there are no numbers to sum up, so the answer is 0\"\"\"\n",
      "    self.assertEqual(sum_positive_numbers([]), 0)\n",
      "\n",
      "\n",
      "def test_case_3(self):\n",
      "    \"\"\"The list contains two positive numbers, so the sum is 42 + 7 = 34\"\"\"\n",
      "    self.assertEqual(sum_positive_numbers([42, -5, 7]), 34)\n",
      "\n",
      "\n",
      "def test_case_4(self):\n",
      "    \"\"\"The list contains one positive number and two negative numbers, so the sum is 0 (since it's not zero, the function should handle this case)\"\"\"\n",
      "    self.assertEqual(sum_positive_numbers([1.5, -2, 3]), 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_unit_tests(test_string):\n",
    "    test_cases = test_string.strip().split('\\n')\n",
    "    test_methods = []\n",
    "\n",
    "    for i, test in enumerate(test_cases):\n",
    "        input_data = re.search(r'Input: (\\[.*?\\])', test).group(1)\n",
    "        output_data = re.search(r'Output: (\\d+)', test).group(1)\n",
    "        explanation = re.search(r'Explanation: (.*)', test).group(1).strip()\n",
    "\n",
    "        test_method = f\"\"\"\n",
    "def test_case_{i+1}(self):\n",
    "    \\\"\\\"\\\"{explanation}\\\"\\\"\\\"\n",
    "    self.assertEqual(sum_positive_numbers({input_data}), {output_data})\n",
    "\"\"\"\n",
    "\n",
    "        test_methods.append(test_method)\n",
    "\n",
    "    return '\\n'.join(test_methods)\n",
    "\n",
    "test_string = \"\"\"- Input: [1, 2, 3] -> Output: 6 -> Explanation: The list contains three positive numbers, so the sum is 1 + 2 + 3 = 6\n",
    "- Input: [] -> Output: 0 -> Explanation: The list is empty, so there are no numbers to sum up, so the answer is 0\n",
    "- Input: [42, -5, 7] -> Output: 34 -> Explanation: The list contains two positive numbers, so the sum is 42 + 7 = 34\n",
    "- Input: [1.5, -2, 3] -> Output: 0 -> Explanation: The list contains one positive number and two negative numbers, so the sum is 0 (since it's not zero, the function should handle this case)\"\"\"\n",
    "\n",
    "unit_tests = convert_to_unit_tests(test_string)\n",
    "print(unit_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91e7ae-8a65-43f0-8e8c-a6b1f713167e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaEnv",
   "language": "python",
   "name": "llamaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
